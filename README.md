# ğŸ›¡ï¸ Deteccion de Anomalias en registros Log

Este proyecto utiliza agentes en LangGraph y un modelo de machine learning para analizar datos de logs de entrada (UNSW-NB15) para identificar diferentes tipos de ataques (DoS, Exploits, Normal)

## Funcionalidades

- Procesamiento de registros estructurados (formato UNSW-NB15)
- ClasificaciÃ³n de registros mediante un modelo de machine learning
- Agentes que coordinan predicciÃ³n y toma de decisiones
- Respuestas estructuradas con acciones sugeridas por registro

## ğŸ—ï¸ Estructura del Proyecto

## ğŸ“ Estructura del Proyecto

```text
agents/                 ğŸ§  LÃ³gica principal de los agentes usando LangGraph
â”œâ”€â”€ tools/              Herramientas o componentes reutilizables (opcional)
â””â”€â”€ keys.py             Claves API para los LLMs (deberÃ­a estar en .gitignore)

app/                    ğŸŒ AplicaciÃ³n FastAPI que expone el agente como servicio API

data/                   ğŸ“‚ (VacÃ­a) Carpeta reservada para archivos de entrada o logs de prueba

models/                 ğŸ¤– CÃ³digo del modelo y exportaciones
â””â”€â”€ exports/            Archivos del modelo exportado (.joblib, .pkl)

notebooks/              ğŸ“’ Notebooks de Jupyter para pruebas, prototipado y anÃ¡lisis exploratorio
```

## ğŸ§© DescripciÃ³n del Funcionamiento

La herramienta estÃ¡ expuesta a travÃ©s de una API que recibe un lote de registros de entrada (logs) con el formato descrito en [ğŸ“¥ Ejemplo de Entrada](#-ejemplo-de-entrada).  

Estos registros pasan por un **flujo de agentes** que consta de dos etapas:

![Flujo de Agentes](agents/agent_flow_mermaid.png)

1. **Agente de Ingesta**  
   Es el encargado de recibir los logs, validarlos, formatearlos y realizar el llamado a la herramienta (`Tool`) disponible. Esta herramienta corresponde a un modelo de Machine Learning previamente entrenado que clasifica cada registro como normal o potencialmente anÃ³malo.

2. **Agente de DecisiÃ³n**  
   Recibe como entrada los resultados de la predicciÃ³n anterior. A partir de ellos, realiza un anÃ¡lisis general del lote y recomienda una acciÃ³n especÃ­fica para cada registro (por ejemplo, "ignorar", "alertar" o "bloquear").

La estructura de la respuesta generada por el agente de decisiÃ³n se describe en [ğŸ“¤ Ejemplo de Salida](#-ejemplo-de-salida).


### ğŸ“¥ Ejemplo de Entrada

```json
[
  {
    "id": 1,
    "dur": 0.12,
    "proto": "tcp",
    "service": "-",
    "state": "FIN",
    "spkts": 6,
    "dpkts": 4,
    ...
  }
]
```

### ğŸ“¤ Ejemplo de Salida

```json
{
  "whole_analysis": "ğŸ§  AnÃ¡lisis general del sistema...",
  "analysis": [
    {"id": 1, "prediction": "NORMAL", "action": "IGNORE"},
    {"id": 2, "prediction": "DOS", "action": "BLOCK"}
  ]
}
```

---

## âš™ï¸ InstalaciÃ³n

### 1. Clona el repositorio
```bash
git clone https://github.com/paulguz261/meli_ai_challenge.git
cd meli_ai_challenge
```

### 2. Crea el archivo 'agents/keys.py' con tus claves API
Este archivo debe definir las siguientes variables:
   - API_KEY_GPT_MELI: tu clave de API de OpenAI
   - API_KEY_GEMINI_MELI: tu clave de API de Gemini

### Contenido de ejemplo para agents/keys.py:
   - API_KEY_GPT_MELI = "tu-clave-api-openai"
   - API_KEY_GEMINI_MELI = "tu-clave-api-gemini"

### 3. Crea y activa el entorno usando Conda
```bash
conda env create -f environment.yml
conda activate meli_ai_env
```

### 4. Inicia el servidor FastAPI
```bash
uvicorn app.main:app --reload
```
